/** * University of Illinois/NCSA * Open Source License *  * Copyright (c) 2008, Board of Trustees-University of Illinois.   * All rights reserved. *  * Developed by:  *  * Automated Learning Group * National Center for Supercomputing Applications * http://www.seasr.org *  *   * Permission is hereby granted, free of charge, to any person obtaining a copy * of this software and associated documentation files (the "Software"), to * deal with the Software without restriction, including without limitation the * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or * sell copies of the Software, and to permit persons to whom the Software is * furnished to do so, subject to the following conditions:  *  *  * Redistributions of source code must retain the above copyright notice, *    this list of conditions and the following disclaimers.  *  *  * Redistributions in binary form must reproduce the above copyright notice, *    this list of conditions and the following disclaimers in the  *    documentation and/or other materials provided with the distribution.  *  *  * Neither the names of Automated Learning Group, The National Center for *    Supercomputing Applications, or University of Illinois, nor the names of *    its contributors may be used to endorse or promote products derived from *    this Software without specific prior written permission.  *  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE * CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS * WITH THE SOFTWARE. */ package org.seasr.components.text.transform;//==============// Java Imports//==============import java.util.*;import java.io.*;import java.util.logging.*;//===============// Other Imports//===============import org.meandre.core.*;import org.meandre.annotations.*;//import org.meandre.tools.components.*;//import org.meandre.tools.components.FlowBuilderAPI.WorkingFlow;import org.seasr.components.text.datatype.corpora.Annotation;import org.seasr.components.text.datatype.corpora.AnnotationConstants;import org.seasr.components.text.datatype.corpora.AnnotationSet;import org.seasr.components.text.datatype.corpora.Document;import org.seasr.components.text.datatype.corpora.FeatureMap;import org.seasr.components.text.datatype.termlist.TermListLite;/** * Overview:  * This module takes in a <i>Document</i> object that has been tokenized and  * outputs a list of the tokens, or terms, and the number of times each  * token appears (frequency count) as a <i>TermList</i> object.  *  *  * Data Type Restrictions:  * The input document must have been tokenized. *  *  * Data Handling:  * This module creates a new TermList object for each document. *  *  * Scalability:  * This module makes one pass over the token list resulting in linear time complexity  * per the number of tokens.  Memory usage is proportional to the number tokens. *  *  * Trigger Criteria:  * Standard. *  *    * @author D. Searsmith * * TODO: Testing, Unit Testing * */@Component(creator = "Duane Searsmith", 		description = "<p>Overview: <br>"+ "This module takes in a Document object that has been tokenized and "+ "outputs a list of the tokens, or terms, and the number of times each "+ "token appears (frequency count) as a TermList object. </p>"+ "<p>Data Type Restrictions: <br>"+ "The input document must have been tokenized.</p>"+ "<p>Data Handling: <br>"+ "This module creates a new TermList object for each document.</p>"+ "<p>Scalability: <br>"+ "This module makes one pass over the token list resulting in linear time complexity "+ "per the number of tokens.  Memory usage is proportional to the number tokens.</p>"+ "<p>Trigger Criteria: <br>"+ "Standard.</p>",	name = "DocToTermList", tags = "text document termlist transform")public class DocToTermList implements ExecutableComponent {	// ==============	// Data Members	// ==============	private int m_docsProcessed = 0;	private static Logger _logger = Logger.getLogger("DocToTermList");	// props		@ComponentProperty(description = "Verbose output?", name = "verbose", defaultValue = "false")	final static String DATA_PROPERTY_VERBOSE = "verbose";	@ComponentProperty(description = "Debug?", name = "debug", defaultValue = "false")	final static String DATA_PROPERTY_DEBUG = "debug";	@ComponentProperty(description = "Clear the document object?", name = "free_doc", defaultValue = "true")	final static String DATA_PROPERTY_FREE_DOC = "free_doc";	@ComponentProperty(description = "Maximum number of tokens.", name = "max_tokens", defaultValue = "-1")	final static String DATA_PROPERTY_TOKEN_LIMIT = "max_tokens";	@ComponentProperty(description = "Title weight.", name = "title_weight", defaultValue = "0")	final static String DATA_PROPERTY_TITLE_WEIGHT = "title_weight";	// IO		@ComponentInput(description = "Document object.", name = "document")	public final static String DATA_INPUT_DOCUMENT = "document";	@ComponentOutput(description = "Term list object.", name = "termlist")	public final static String DATA_OUTPUT_TERMLIST = "termlist";	// ================	// Static Methods	// ================	/**	 * Test	 */		static public void main(String[] args) {//		// get a flow builder instance//		FlowBuilderAPI flowBuilder = new FlowBuilderAPI();//		// get a flow object//		WorkingFlow wflow = flowBuilder.newWorkingFlow("test");//		// add a component//		String pushString = wflow//				.addComponent("org.seasr.meandre.components.io.PushString");//		// set a component property//		wflow.setComponentInstanceProp(pushString, "string",//				"http://norma.ncsa.uiuc.edu/public-dav/capitanu");//		// add another component//		String reader = wflow//				.addComponent("org.seasr.meandre.components.t2k.io.file.ReadFileNames");//		wflow.setComponentInstanceProp(reader, DATA_PROPERTY_FILTER, ".*\\.xml");//        wflow.setComponentInstanceProp(reader, DATA_PROPERTY_WEBDAV, "true");//		// make a connection between two components//		wflow.connectComponents(pushString, "output_string", reader,//				DATA_INPUT_DIRNAME);////		// execute the flow specifying that we want a web UI displayed//		flowBuilder.execute(wflow, false);////		// For some reason the process does not end without a forced exit.//		System.exit(0);	}		// ================	// Constructor(s)	// ================	public DocToTermList() {	}	// ================	// Public Methods	// ================	public boolean getVerbose(ComponentContextProperties ccp) {		String s = ccp.getProperty(DATA_PROPERTY_VERBOSE);		return Boolean.parseBoolean(s.toLowerCase());	}	public boolean getDebug(ComponentContextProperties ccp) {		String s = ccp.getProperty(DATA_PROPERTY_DEBUG);		return Boolean.parseBoolean(s.toLowerCase());	}	public boolean getFreeDoc(ComponentContextProperties ccp) {		String s = ccp.getProperty(DATA_PROPERTY_FREE_DOC);		return Boolean.parseBoolean(s.toLowerCase());	}	public int getTokenLimit(ComponentContextProperties ccp) {		String s = ccp.getProperty(DATA_PROPERTY_TOKEN_LIMIT);		return Integer.parseInt(s);	}	public int getTitleWeight(ComponentContextProperties ccp) {		String s = ccp.getProperty(DATA_PROPERTY_TITLE_WEIGHT);		return Integer.parseInt(s);	}	// =====================================	// Interface Impl: ExecutableComponent	// =====================================	/* (non-Javadoc)	 * @see org.meandre.core.ExecutableComponent#initialize(org.meandre.core.ComponentContextProperties)	 */	public void initialize(ComponentContextProperties ccp) {		_logger.fine("initialize() called");		m_docsProcessed = 0;	}	/* (non-Javadoc)	 * @see org.meandre.core.ExecutableComponent#dispose(org.meandre.core.ComponentContextProperties)	 */	public void dispose(ComponentContextProperties ccp) {		_logger.fine("dispose() called");		if (getVerbose(ccp) || getDebug(ccp)) {			_logger.info("\nEND EXEC -- DocumentToTermList -- Docs Processed: "							+ m_docsProcessed + "\n");		}		m_docsProcessed = 0;	}		/**	 * 	 * In frequency include all occurrences of a term even if it only matches	 * the POS tag criteria	 * 	 * for a subset of occurrences.	 * 	 */	/* 	 * In frequency include all occurrences of a term even if it only matches	 * the POS tag criteria for a subset of occurrences.	 * 	 * (non-Javadoc)	 * @see org.meandre.core.ExecutableComponent#execute(org.meandre.core.ComponentContext)	 */	@SuppressWarnings("unchecked")	public void execute(ComponentContext ctx)			throws ComponentExecutionException, ComponentContextException {		_logger.fine("execute() called");		int tokens_processed = 0;		try {			Document doc = (Document) ctx.getDataComponentFromInput(DATA_INPUT_DOCUMENT);			if (getDebug(ctx)) {				_logger.info("Document: "						+ doc.getDocID()						+ " has "						+ doc.getAnnotations().get(								AnnotationConstants.TOKEN_ANNOT_TYPE).size()						+ " tokens.");			}			AnnotationSet annots = doc.getAnnotations();			HashMap<String, Object[]> map = new HashMap<String, Object[]>();			for (Iterator<Annotation> iter = annots.iterator(); iter.hasNext();) {				Annotation tok = iter.next();				if (tok.getType().equals(AnnotationConstants.TOKEN_ANNOT_TYPE)) {					String tokimg = (String) tok.getFeatures().get(							AnnotationConstants.TOKEN_ANNOT_FEAT_NORM_IMAGE);					String otokimg = tok.getContent(doc);										if (tokimg == null) {						tokimg = otokimg;					}					if (tokimg.length() > 0) {						Object[] obarr = map.get(tokimg);						if (obarr == null) {							obarr = new Object[5];							obarr[0] = tokimg;							obarr[1] = new Integer(1);							HashSet<String> set = new HashSet<String>();							set.add(otokimg);							obarr[2] = set;							obarr[3] = new Boolean(false);							if (tok									.getFeatures()									.containsKey(											AnnotationConstants.TOKEN_ANNOT_FEAT_WEIGHT)) {								obarr[4] = tok										.getFeatures()										.get(												AnnotationConstants.TOKEN_ANNOT_FEAT_WEIGHT);							} else {								obarr[4] = null;							}							map.put(tokimg, obarr);						} else {							obarr[1] = new Integer(((Integer) obarr[1])									.intValue() + 1);							((Set) obarr[2]).add(otokimg);						}						if (tok.getFeatures().get(								AnnotationConstants.TOKEN_ANNOT_FEAT_INTITLE) != null) {							obarr[3] = new Boolean(true);						}						tokens_processed++;					}				}			}			// for ngrams			for (Iterator<Annotation> iter = annots.iterator(); iter.hasNext();) {				Annotation tok = iter.next();				if (tok.getType().equals(AnnotationConstants.NGRAM_ANNOT_TYPE)) {					String tokimg = (String) tok.getFeatures().get(							AnnotationConstants.NGRAM_ANNOT_FEAT_NORM_IMAGE);					String otokimg = tok.getContent(doc);					if (tokimg == null) {						tokimg = otokimg;					}					if (tokimg.length() > 0) {						Object[] obarr = (Object[]) map.get(tokimg);						if (obarr == null) {							obarr = new Object[5];							obarr[0] = tokimg;							obarr[1] = new Integer(1);							HashSet<String> set = new HashSet<String>();							set.add(otokimg);							obarr[2] = set;							obarr[3] = new Boolean(false);							if (tok									.getFeatures()									.containsKey(											AnnotationConstants.TOKEN_ANNOT_FEAT_WEIGHT)) {								obarr[4] = tok										.getFeatures()										.get(												AnnotationConstants.TOKEN_ANNOT_FEAT_WEIGHT);							} else {								obarr[4] = null;							}							map.put(tokimg, obarr);						} else {							obarr[1] = new Integer(((Integer) obarr[1])									.intValue() + 1);							Set<String> shold = (Set<String>) obarr[2];							shold.add(otokimg);						}						tokens_processed++;					}				}			}			// Now sort by freq descending			TreeSet<Object[]> ts = new TreeSet<Object[]>(new TokElementComparator());			ts.addAll(map.values());			// load into TermListLite			TermListLite tlist = new TermListLite();			int cnt = Integer.MAX_VALUE;			if (this.getTokenLimit(ctx) > 0) {				cnt = this.getTokenLimit(ctx);			}			for (Iterator<Object[]> it = ts.iterator(); it.hasNext() && (cnt > 0); cnt--) {				Object[] obarr = it.next();				int freq = ((Integer) obarr[1]).intValue();				if (((Boolean) obarr[3]).booleanValue()) {					freq += this.getTitleWeight(ctx);				}				if (obarr[4] != null) {					freq = freq * ((Integer) obarr[4]).intValue();				}				if (freq > 0) {					tlist.addTerm((String) obarr[0], freq, new ArrayList<String>(							(Collection<String>) obarr[2]));				}			}			tlist.setDocID(doc.getDocID());			tlist.setTitle(doc.getTitle());			tlist.setDate(doc.getDate());			try {				tlist.setProperties(doc.getFeatures());				if (getVerbose(ctx) || getDebug(ctx))					_logger.info("DocToTermList: set properties successfully");			} catch (NullPointerException e) {				try {					FeatureMap fMap = doc.getFeatures();					Iterator keys = fMap.keySet().iterator();					Map newMap = new HashMap();					while (keys.hasNext()) {						String key = (String) keys.next();						Object value = fMap.get(key);						if (value != null) {							newMap.put(key, value);						} else {							if (this.getVerbose(ctx))								_logger.info("DocToTermList: removed property key - "												+ key												+ " cause it had a null value (for document "												+ doc.getDocID() + ".");						}					}// while					tlist.setProperties(newMap);					if (this.getVerbose(ctx) || getDebug(ctx))						_logger.info("DocToTermList: set properties successfully for document "								+ doc.getDocID());				} catch (Exception ex) {					_logger.severe("DocToTermList: " + doc.getDocID());					ex.printStackTrace();				}			}			if (getVerbose(ctx)||getDebug(ctx)) {				_logger.info(tokens_processed						+ " tokens were processed for this document -- "						+ tlist.getTitle());				_logger.info("# terms in list: " + tlist.getSize()						+ "\n\n");			}			if (getFreeDoc(ctx)) {				doc.free();			}			ctx.pushDataComponentToOutput(DATA_OUTPUT_TERMLIST, tlist);			m_docsProcessed++;		} catch (Exception ex) {			ex.printStackTrace();			_logger.severe(ex.getMessage());			_logger.severe("ERROR: DocToTermList.execute()");			throw new ComponentExecutionException(ex);		}	}	// =============	// Inner Class	// =============	public class TokElementComparator implements Comparator<Object[]>, Serializable {		private static final long serialVersionUID = 1L;		/**		 * 		 * put your documentation comment here		 * 		 */		public TokElementComparator() {		}		// ======================		// Interface: Comparator		// ======================		public int compare(Object[] o1, Object[] o2) {			int pos1 = ((Integer) o1[1]).intValue();			int pos2 = ((Integer) o2[1]).intValue();			if (pos1 < pos2) {				return 1;			} else if (pos1 > pos2) {				return -1;			} else {				return ((String) ((Object[]) o1)[0])						.compareTo((String) ((Object[]) o2)[0]);			}		}		/**		 * 		 * put your documentation comment here		 * 		 * @param o		 * 		 * @return		 * 		 */		public boolean equals(Object o) {			return this.equals(o);		}	}}